Here is a detailed start.md file you can include at the root of your repository. This README is tailored for use with GitHub Copilot/Codex and assumes youâ€™re setting up a scalable Docker-based Stable Diffusion API service.

â¸»


# ğŸš€ Stable Diffusion API Service with Auto-Scaling Support

This repository sets up a **Dockerized Stable Diffusion API service** optimized for:

- âœ… Real-time image generation from text prompts
- ğŸ¾ Animal portraits, ğŸ•Šï¸ biblical scenes, ğŸ  real estate marketing stills
- âš™ï¸ FastAPI-compatible API
- ğŸ“¦ Supports SDXL, LoRAs, ESRGAN upscaling
- ğŸ“ˆ Spin up multiple containers for concurrent video generation workflows
- ğŸ›‘ Graceful shutdown when containers are idle or complete

---

## ğŸ“ Project Structure

stable-diffusion-api/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ start.md        <â€“ You are here
â”œâ”€â”€ models/         <â€“ Mount your SDXL, LoRA, ESRGAN, etc.
â””â”€â”€ output/         <â€“ Rendered images will be stored here

---

## ğŸ”§ Prerequisites

- âœ… Ubuntu 20.04+ (already installed)
- âœ… Docker + Docker Compose
- âœ… NVIDIA drivers + CUDA Toolkit
- âœ… Models downloaded to `./models` directory
  - Examples:
    - `models/Stable-diffusion/sd_xl_base_1.0.safetensors`
    - `models/Lora/real_estate_style.safetensors`
    - `models/ESRGAN/R-ESRGAN-4x.pth`

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone This Repository

```bash
git clone https://github.com/your-username/stable-diffusion-api.git
cd stable-diffusion-api

2. Prepare Volumes

Place your models in:

mkdir -p models/Stable-diffusion
mkdir -p output

Then move your .safetensors and .ckpt files into the appropriate folders.

â¸»

3. Build the Docker Image

```bash
docker compose build
```


â¸»

4. Run the Service

Option A: Run One Instance


```bash
docker compose up -d
```

> **Tip:** Older installations using `docker-compose` may throw `KeyError: 'ContainerConfig'` during build.
> Disable BuildKit to work around it:
>
> ```bash
> export DOCKER_BUILDKIT=0 COMPOSE_DOCKER_CLI_BUILD=0
> docker-compose up -d
> ```


Service will be available at (default port **8000**, configurable via `PORT` env variable):
â¡ï¸ http://localhost:8000/docs (FastAPI docs)
â¡ï¸ POST `/txt2img` to generate an image
â¡ï¸ GET `/files/{filename}` to download generated images

Option B: Scale Multiple Instances

```bash
docker compose up -d --scale sd-api=3
```

You can then load-balance or assign containers to parallel workloads.

â¸»

ğŸ§ª Example API Call

```bash
curl -X POST 'http://localhost:8000/txt2img?prompt=a%20rustic%20house%20at%20sunset&width=768&height=512&steps=28&guidance=7.0'
```

Response:

```json
{ "ok": true, "path": "/output/out-<id>.png", "url": "http://localhost:8000/files/out-<id>.png" }
```

You can then download with:

```bash
wget http://localhost:8000/files/out-<id>.png -O out.png
```

All images are also saved to the host-mounted `./output` directory.

â¸»

ğŸ”„ Stopping & Scaling Down

To shut down all containers:

```bash
docker compose down
```

To scale up/down:

```bash
docker compose up -d --scale sd-api=N
```

To monitor resource usage:

docker stats


â¸»

ğŸš¦ Optional: Auto-Scaling with Python

Use the Docker SDK to programmatically scale containers:

import docker
client = docker.from_env()
service = client.services.get("sd-api")
service.scale(5)  # spin up 5 containers


â¸»

ğŸ“Œ TODO / Roadmap
	â€¢	Add NGINX gateway for load-balanced access to multiple API instances
	â€¢	GPU load detection for auto-scaling based on video pipeline workload
	â€¢	Healthcheck endpoint for container lifecycle management
	â€¢	Mount logging directory for monitoring/stats
	â€¢	Add authentication token for secured inference API

â¸»

ğŸ“œ License

MIT License.

â¸»

âœï¸ Bless this build to serve your vision with clarity and beauty.
